[#sec:partitioning]
## Partitioning

Safety standards define processes of safety assessment and hazard analysis to
allow each task to be categorized according to its criticality, e.g. ASIL levels
in ISO 26262, DAL levels in DO-178, software criticality categories in ECSS.
In a given system, if the tasks that share hardware resources vary in their
criticality levels, or if safety critical and non-safety critical tasks can
coexist, the system is said to be of mixed-criticality.

The criticality of a task and the standard according to which its code is
developed have a direct impact on the number of safety mechanisms that need to
be implemented. As a consequence, the acceptable error rates of the tasks differ
according to their criticality level.
To prevent a less/non critical task from interfering with the execution of a
more critical task, it is therefore required to ensure freedom from such
interference.

Even if the tasks have the same criticality level, it is sometimes necessary to
ensure freedom from interference if the tasks rely on each other to perform some
safety function.
Such cases could be exposed, for example, by a dependent failure analysis, as it
is the case with ISO 26262.

Freedom from interference can be implemented by space partitioning, time
partitioning, or a mixture of the two.

In time partitioning, the hardware resources are only used by one task at any
given time, but during that time each task is able to make use of all the
resources available.
This requires a task scheduler, for example as part of a real-time operating
system, to ensure tasks are prioritized according to the properties defined by
the system designer, such as the criticality level and priority.

Space partitioning refers to the exclusive assignment of a subset of the
hardware resources to each task.
In traditional single-core systems, the term “space partitioning” only implies
memory space partitioning, as the allocation of the single processor core for
some time also grants access to all other resources of the system.
This is no longer the case in multicore systems where several cores can
simultaneously access shared hardware resources.
The space partitioning could be statically defined at configuration time, or it
could be dynamically chosen at execution time. Space partitioning is sometimes
supported in software through the use of a hypervisor or directly by the
operating system.

Hardware resources to be partitioned may include processing capacity (e.g.,
CPUs, GPUs, NPUs, TPUs, etc.), memory, cache, interconnect and I/O devices.

In this document, we cover memory space partitioning as well as the partitioning
of other resources as part of the space partitioning. 

[#sec:partitioning:safety]
### Safety needs

Both space and time partitioning rely on the availability of hardware features
to support them.

[#sec:partitioning:safety:time]
#### Time partitioning

Time partitioning is the avoidance or reduction of interference of applications
running on the same system by mechanisms that ensure only one application is
running on the shared resource at a given point in time.

Time partitioning is an essential method in safety-critical systems that is used
to enable the integration of multiple applications and/or tasks, generally with
real-time requirements, on the same system.
Time partitioning, if enforced to a sufficient extent, provides a number of
advantages:

* It allows verifying each application independently - in the time domain - and
  integrating them together in a time-composable or, at least, in a
  time-compositional manner.
  In particular, time composability is achieved when the timing bounds obtained
  in isolation hold upon integration.
  Time compositionality, instead, holds when timing bounds can only change upon
  composition in a controlled and known-beforehand manner, therefore, avoiding
  the re-verification of the timing bounds of the composition.
* It also allows decreasing the risk of deadline overruns during operation since
  timing impacts  across different tasks are significantly decreased.

On multi-core SOCs, time partitioning of tasks should be applied individually to
a single core as well as combinations of multiple cores.
Time partitioning is key to allow tasks to start, with some degree of precision,
when required, as well as to ensure they make sufficient progress to meet their
deadlines.

[#sec:partitioning:safety:time:features]
##### Features

The features to be addressed by time partitioning relate to guaranteeing
specific start times and progress of tasks, as discussed above.
In particular, time partitioning should provide the following features:

* Periodic timer(s). Deadlines can only be respected if tasks' start times can
be enforced so that they start sufficiently ahead of their deadlines.
Hence, controlling, with some degree of precision, when tasks are started is a
fundamental requirement.
The existence of periodic timer(s) allows the task scheduler to have a precise
notion of time.
Hence, by properly configuring those timers, normally by means of primitives
used by the scheduler, a given task schedule can be enforced.
+
Timers must provide a sufficient degree of precision with respect to the
granularity at which time must be controlled.
For instance, a timer providing millisecond-level precision would be useless
for decisions requiring microsecond-level precision.
+
Timing control is key across domains. For instance, Integrated Modular
Avionics (IMA) relies on timing partitions referred to as MAjor Frames (MAFs)
and MInor Frames (MIFs) whose duration is predetermined by the schedule.
Hence, timers that allow the start of MAFs and MIFs at their required times
with sufficient precision are a mandatory feature.
Analogously, in the automotive domain, applications may have different tasks
running at different frequencies, which require either multiple timers or, at
least, a sufficiently precise timer to trigger the start of all tasks when
needed to meet their execution frequencies and deadlines.
+
Depending on the technical solution, periodic timer(s) can be replaced by a
one-shot timer that is reloaded on demand by the tickless scheduler, such as
Linux CLOCK_EVT_FEAT_ONESHOT feature.

* Intra-core time partitioning.
Tasks' progress in a given core is impacted by the initial state of the
allocated resources (e.g. cache memories), and also can be impacted if their
execution can be preempted.
Some of that impact, which causes a given task to be scheduled out of the core,
is unavoidable and the direct result of the scheduling decisions.
However, other impacts are undesirable and potentially avoidable, such as those
related to the change of the state of the processor between the instant when the
task is scheduled out of it and the instant when it is scheduled back in.
This state includes the contents of cache memories, the state of the replacement
information in those caches, the contents of the branch predictors, occupancy of
queues and buffers, etc.
+
Features related to the ability to reset, flush or freeze the state of the
hardware resources in use by a given task provide support for time partitioning.
For instance, the ability to reset the processor state to a given known state
reduces time variability as the state is known when starting the execution of a
task.
Otherwise, effects like unforeseen systematic branch mispredictions or
unfortunate cache miss patterns could occur if the execution of another task is
started or resumed with the processor state (e.g. branch predictor state, cache
replacement state) "as is" after the execution of a previous task.
The time required for resetting, flushing or freezing processor states should be
accounted for in the scheduling.
+
In some specific domains, such as avionics, some of these features are often
used across time partitions.
For instance, flushing cache contents may be used across MAFs  so that all MAFs
start with the same initial state.
+
For the sake of illustration, we list some specific features contributing to
intra-core time partitioning, although the list is non-exhaustive:

** Cache flushing is particularly useful to evict dirty lines in write-back
caches after a task has executed, so that the associated overhead of those
evictions does not impact the next task being scheduled.
** Cache locking (of a line, way or the full cache) can be used to mitigate the
impact of preemption with the side effect of having cache lines which cannot be
used by other tasks (because they are locked).
** Resetting the replacement policy (such as LRU) state and branch predictor
state avoids systematic bad behavior such as branch mispredictions or cache
misses occurring unexpectedly.
If the state reset has a negative impact on performance, such impact should
already be accounted for during verification phases since such state is known.
** Stateless features such as pseudo-random replacement policies for caches
are preferred because every state of the replacement policy is probabilistically
equivalent, so there is no need for resets.

* Inter-core time partitioning.
Tasks' progress is also impacted by the software running concurrently on other
cores, which may compete for shared resources (e.g. a shared peripheral).
The following time partitioning features can mitigate or remove altogether such
mutual interference.
+
Often, time partitioning across cores is implemented at the software level (e.g.
in the real-time operating system).
For the sake of illustration, we list some specific techniques contributing to
inter-core time partitioning, although the list is non-exhaustive:

** Time Division Multiple Access (TDMA), where resource ownership is allocated
exclusively to each core for a given time duration, following specific
allocation patterns.
This technique is a way to provide time isolation across tasks running on
different cores, which is a specific form of time partitioning.
The simplest scheme uses a round-robin algorithm with time slots of homogeneous
duration.
This scheme guarantees forward progress and bandwidth to each core.
+
There are two ways to realize TDMA: as a work conserving policy and as a
non-work conserving policy.
The highest degree of isolation is achieved with a non-work conserving approach,
where slots are allocated exclusively regardless of whether they are used or
not.
However, such a policy has low efficiency since cores willing to access the TDMA
"protected" resource may be waiting for their slots to arrive while the resource
is idle.
A work-conserving approach allocates slots following the TDMA scheme, but if a
core is not using the resource whenever granted access, the grant is given to
the following core in the TDMA order.
Such a policy increases utilization, but may reduce isolation since a core
requesting the resource may miss out on a slot because the request did not
arrive in the first cycle of the slot, and the next core in the TDMA order had a
request ready.
In the worst case, specific access patterns may therefore systematically cause a
core to wait for all the other cores to access the resource first.
+
In any case, if TDMA is implemented at software level and sufficiently coarse
granularity (e.g., to grant access to a specific peripheral), there is high
flexibility to implement time partitioning while preserving some fairness in
task execution.

** An alternative way to achieve time partitioning consists of allocating access
or usage quotas.
This type of time partitioning provides generally higher efficiency than TDMA,
but no isolation.
In particular, tasks may be allocated a given number of accesses or time
utilization for some shared resources (either hardware or software) during a
given time period and, if a task exhausts its allocated amount (a.k.a. quota),
then it is not allowed to further access the resource during the current time
period.
Note that, while quotas can be implemented at software level for resources whose
utilization can be monitored in software, they may also require hardware support
such as access counters and stall cycles which are monitored through performance
monitoring counters.
Building on those counters, and especially if they report separate events per
core, software can easily allocate quotas and monitor utilization.

* OS support for time partitioning.
In the absence of appropriate hardware support, or if strict time partitioning
is not needed at least for all tasks, some OSs can provide enough time
partitioning support.
For instance, priorities and preemption can allow critical tasks with real-time
requirements achieve some degree of time partitioning (e.g. scheduled with the
highest priority and with preemption enabled), while allowing other tasks (e.g.
scheduled with lower priorities) to run with lower or no time guarantees at all.

[#sec:partitioning:safety:time:level]
##### Level

Periodic timer(s) are generally implemented at SoC level to provide a
homogeneous view of time across all components on chip (e.g. across all cores).
It is also possible to have core-local timers, but they likely require some form
of mutual synchronization, either directly among them or through a SoC-global
timer.

Intra-core time partitioning features are normally implemented at core level if
resources are local to the core, or at SoC level if resources are shared across
cores.
For instance, flushing cache contents for an on-core first level cache would be
a core-level feature, whereas flushing the buffers and queues of an interconnect
would be a SoC-level feature.

Inter-core time partitioning features are often implemented at software level,
generally building on the aforementioned intra-core timers.
For instance, the operating system may program a given peripheral to accept
requests from a single core (owner core) at a time, periodically switching the
owner core.
However, such features may also be implemented at SoC level.
Some peripherals may implement TDMA or other arbitration policies providing some
form of time partitioning.

[#sec:partitioning:safety:mem]
#### Memory space partitioning

Much like time partitioning, memory space partitioning is a fundamental
prerequisite for the integration of different applications in the same system in
order to avoid unintended interference.
Reliable protection at the spatial level ensures that one component cannot alter
the code or private data of another component, which is a key requirement in
safety-critical systems.
Space partitioning also applies to memory-mapped peripherals and memory
transactions initiated by peripherals (through DMA...).
Memory space partitioning relies on the creation of a separate memory address
space for each task and limiting or disabling the reading, writing or execution
of code/data in address spaces that belong to different tasks. 

Additionally, main memory is a major shared resource among cores in a multicore
system.
If phenomena such as race conditions are not controlled in an effective way, the
system can become highly unpredictable.
Memory partitioning and sharing is therefore one of the critical aspects that
have an impact on the predictability of systems making use of multicore
processors.

However, in this section we are concerned not just with CPU memory but any kind
of memory, e.g. supporting a GPU.

Other aspects, such as the management of the communication channels'
interference or other shared resources besides memory are out of the scope of
this section.

[#sec:partitioning:safety:mem:features]
##### Features

The features to be addressed related to memory space partitioning are heavily
dependent on the design of the core/SoC and the rules enforced by the hypervisor
or the operating system.
The following is a subset of some suggested features that should be considered:

* Architecture primitives for space partitioning used to allow the firmware to
specify physical memory regions and control the memory access permissions.
Currently, most devices have a basic memory protection module, such as an MPU
(Memory Protection Unit) or PMP (Physical Memory Protection) in the RISC-V
lingo.
Typically, such memory protection primitives are needed to restrict some memory
regions to the software running under less privileged modes.
This feature is especially useful in the scope of real-time operating systems,
where it must provide space isolation for partitions that host different
applications.
In addition, handlers that are triggered when memory access faults are produced
can be considered.
+
Primitives for space partitioning can also apply for space separation of
Input/Output (I/O) components: if a guest can directly access an I/O device,
then it can potentially request the device to access memory that it is not
entitled to via direct memory access.
Ensuring that partitions do not access each other's memory indirectly through
the shared I/O devices in the system, e.g. through an IOMPU (which can have many
names and flavours across silicon makers but is standardized as IOPMP in the
RISC-V lingo), is especially important in safety-critical systems.

* A memory management unit with different privilege level access permissions is
necessary when implementing a Linux-like OS, a separation kernel, a hypervisor
or a virtualization solution.
In virtualization, physical resources are shared among tasks, therefore it is a
requirement that the virtualized hardware provides a similar level of isolation
between the tasks.
This protection mechanism must ensure that although multiple tasks share the
main memory, a task cannot write into the memory address space of another user
task or the operating system.
+
Much like previously stated, memory protection from other devices can be
provided at I/O management.
I/O memory management units (IOMMUs) prevent partitions or guest operating
systems from requesting I/O devices to access memory that are not entitled to
access, while still allowing them to directly access the device.
In addition, mechanisms may be required to ensure that table walks of lower
priority tasks do not block the ones of safety-critical tasks, to avoid their
starvation or a downgrade in their performance when accessing the IOMMU.

* Memory modules that are more local to a core or a subset of cores, such as
scratchpad memory (SPM), non-cached memories or private CPU memories, can be
used to enforce spatial isolation.

These mechanisms can also be used to safely share memory areas when required by
the system.

To allow this, particularly in multicore systems, we require supporting features
such as:

* Protection of memory space and peripherals used by safety-critical tasks,
which could be accomplished by means of hardware or software spinlocks,
barriers, process affinity attributes and other synchronization and protection
mechanisms at a SoC level;
* Atomic operations support at core level implement read-modify-write sequences
that are performed without interference from another requester.

[#sec:partitioning:safety:mem:level]
##### Level

Solutions for memory partitioning will have an impact on the core, SoC, or
software levels depending on the targeted resource/functionality (e.g.
partitioning primitives, different types of memory, atomic operations,
virtualization, etc.).
Changes at the core and/or SoC levels could have an impact at the software
level, which could be simple and of limited scope (e.g. adding some instructions
in the code of the hypervisor/OS/RTOS) or complex and impact multiple elements
of the software stack (e.g. major changes in the hypervisor/OS/RTOS and
re-architecture of the applications code).

[#sec:partitioning:safety:other]
#### Partitioning resources other than memory

The described time and memory space partitioning features are not always
sufficient to ensure the determinism of a system. Interference can arise in
systems for other reasons.
The use of stateful and/or shared mechanisms in processor designs can cause
interference that impacts the determinism of applications and the system.
An example of a mechanism that falls under the two categories (stateful and
shared) is the branch predictor.
The stateful property of the branch predictor makes the computation of WCET
difficult or inaccurate (overestimated), as the computation of all the possible
states for each branch in an application is complex or impossible (e.g.
interactive application).
Furthermore, the shared property renders WCET computation even more complex.

The impact of such interference doesn't need to be time, as in the above
explained example of the branch predictor.
For example, integrity of the data can also be impacted.
In the security domain, attacks like RowHammer have shown that the data from one
application could be corrupted by another application.
While in the safety domain malicious actions from applications are not
considered, the impact of such actions should be considered in order to maintain
the reliability of the memory and the integrity of the data of the different
applications in the system.
In fact, a number of safety and security concerns have analogous consequences,
and differ only on whether the root cause is unintended (safety concern) or
malicious (security concern).

[#sec:partitioning:safety:other:features]
##### Features

The features to be addressed concerning the partitioning of other resources are
heavily dependent on the design of the core and SoC, and rules enforced by the
hypervisor or the operating system.
The following is a subset of some suggested features that should be considered:

* Configuration of hardware prediction or speculative mechanisms typically used
to enhance the core/processor performance.
Some representative examples include the branch predictor, the speculative
execution engine, and the memory transactions reordering mechanisms.
When present these mechanisms should be configurable or have the capability to
be deactivated in order to reduce their interferences and increase the
determinism of the system.
* In multicore SoCs, integrating applications of different criticality levels by
having cores dedicated to certain criticality levels will reduce the impact of
the less critical applications on the more critical ones.
Alternatively, defining the core affinity of a task, or core(s) allocation to a
partition by a hypervisor can enable the control of such interferences.
* Interconnect minimizing interference channels, notably access ports where
several paths can converge.
A single bus is an important interference channel as it supports only one
transaction at a time, whereas a network-on-chip with multiple paths may allow
multiple simultaneous transactions without interference.
* Ability to route interrupt sources to dedicated cores, to ensure that these
interrupts are handled promptly and don't disrupt the execution of critical
applications running in other cores.
* Explicit communication between partitions, as any implicit mechanism (for
example threads sharing global variables, or cache coherency) are difficult to
monitor and to predict.
For example, critical systems hypervisors (e.g. ARINC-653 hypervisors) may
provide inter-partition communication mechanisms such as queueing ports and
sampling ports.
* Shared peripherals, including I/O interfaces, accelerators (such as DSP, GPU,
neural network coprocessor, etc.) and DMAs.
Transaction initiators could be considered like processor cores, as they may
introduce concurrent traffic on interference channels.
Peripherals could be allocated to a core, or specific sharing mechanisms could
be used.
* Cache coherency mechanisms, centralized (e.g. snooping) vs. distributed (e.g.
directory-based) and the associated additional traffic should be considered when
analyzing interference channels.
* In addition, performance counters (see other chapter) can be used to implement
interference monitoring (refer to the chapter dedicated to performance
counters).

[#sec:partitioning:safety:other:level]
##### Level

Like for memory partitioning, solutions for the partitioning of other resources
will have an impact on the core, SoC, or software levels depending on the
targeted resource/functionality (e.g. branch predictor, interconnect,
interrupts, explicit communication, etc.).
Changes at the core and/or SoC levels could have an impact at the software
level, which could be simple and of limited scope (e.g. adding some instructions
in the code of the hypervisor/OS/RTOS) or complex and impact multiple elements
of the software stack (e.g. major changes in the hypervisor/OS/RTOS and
re-architecture of the applications code).

[#sec:partitioning:safety:importance]
#### Importance

If more than one application or process needs to coexist on the same platform,
then partitioning is currently the state-of-the-art solution to mitigate
interference channels, which is required at every criticality level.

[#sec:partitioning:safety:justification]
#### Justification

Without partitioning, a task (referred to as application in CAST32A) may delay
another by creating contention over a shared resource, which could be processor
cycles or any of the physical resources.
This leads to a reduction in the availability of the system.

Without partitioning, the integrity and confidentiality of each process may also
be affected, for example if its memory is overwritten by another process.

In avionics, the CAST32A guideline mandates that all interference channels must
be identified and mitigated.
A task of any criticality shall not impact the execution of another application,
including its execution time (robust partitioning).

In automotive, ISO26262 part 6 (software) identifies freedom from interference
as a requirement across different software partitions.
Annex D further lists relevant faults that can arise upon the lack of freedom
from interference as follows:

* Timing and execution faults: blocking of execution, deadlocks, livelocks,
incorrect allocation of execution time (i.e. exceeding allocated time budgets),
and incorrect synchronization across software elements.
* Memory: corruption of content, and read or write access to memory allocated
to another software element (unauthorized access to memory regions with
arbitrary consequences).
* Exchange of information: concerns such as repetition, loss, delay, insertion,
masquerade, incorrect sequence, corruption, blocking access to a communication
channel, and failure to send/receive information to/from appropriate
receivers/senders.

ISO26262 also mandates dependent failure analysis to identify and limit the
impact of a failure, which aims to make the system more reliable.
Partitioning is likely to be mandated as an outcome of this analysis.
